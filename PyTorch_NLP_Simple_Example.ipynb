{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_NLP_Simple_Example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPEoxLMf8wKV1WZo+aNlMmx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriprad/PyTorch/blob/master/PyTorch_NLP_Simple_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ7RoOA3ZoRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyQD_lfZbQ9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
        "        (\"Give it to me\".split(), \"ENGLISH\"),\n",
        "        (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
        "        (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
        "\n",
        "test_data = [(\"Yo creo que si\".split(), \"SPANISH\"),\n",
        "             (\"it is lost on me\".split(), \"ENGLISH\")]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq2OfZ5BbWVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be876cac-a0d9-489c-dfd2-e1714df9baaf"
      },
      "source": [
        "word_to_ix = {}\n",
        "for sent,_ in data + test_data:\n",
        "  for word in sent:\n",
        "    if word not in word_to_ix:\n",
        "      word_to_ix[word] = len(word_to_ix)\n",
        "print(len(word_to_ix))\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "NUM_LABELS = 2"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCkKt9subrwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoWClassifier(nn.Module):\n",
        "  def __init__(self, num_labels, vocab_size):\n",
        "    super(BoWClassifier, self).__init__()\n",
        "    self.linear = nn.Linear(vocab_size, num_labels)\n",
        "  def forward(self, bow_vec):\n",
        "        # Pass the input through the linear layer,\n",
        "        # then pass that through log_softmax.\n",
        "        # Many non-linearities and other functions are in torch.nn.functional\n",
        "        return F.log_softmax(self.linear(bow_vec), dim=1)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6cVMSGZll17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence:\n",
        "        vec[word_to_ix[word]] += 1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "\n",
        "def make_target(label, label_to_ix):\n",
        "    return torch.LongTensor([label_to_ix[label]])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ9sjzRJlwxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUQTV0sXl6eU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "45fc6971-5a37-437e-b0b5-c4bce2f4cc68"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BoWClassifier(\n",
            "  (linear): Linear(in_features=26, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrMG0Ff-mBMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b4b36f44-a593-45e8-9176-c15cef87b100"
      },
      "source": [
        "for param in model.parameters():\n",
        "    print(param)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1404, -0.0277,  0.1930,  0.0239,  0.0774,  0.1043,  0.1034,  0.1845,\n",
            "          0.1141, -0.1145,  0.0058, -0.0026,  0.0534, -0.0945,  0.0879, -0.0444,\n",
            "         -0.0228,  0.1806,  0.1394,  0.0025, -0.1180,  0.1380,  0.0591,  0.0620,\n",
            "          0.1470,  0.1896],\n",
            "        [ 0.1142, -0.0696,  0.1824, -0.1568, -0.1755,  0.0968,  0.0269,  0.0478,\n",
            "         -0.1813, -0.0890,  0.0782, -0.1411, -0.1222, -0.0904,  0.0798, -0.1221,\n",
            "         -0.0599,  0.1755, -0.1095, -0.0241, -0.0999, -0.0508, -0.0643,  0.1308,\n",
            "          0.1377,  0.0857]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.1289, -0.0470], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8H1OXnEmNiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc62d3af-ce79-4379-a112-93df8a1d7489"
      },
      "source": [
        "with torch.no_grad():\n",
        "    sample = data[0]\n",
        "    bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
        "    log_probs = model(bow_vector)\n",
        "    print(log_probs)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5071, -0.9219]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deoFtXLYmbtv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f090c125-c239-45f3-c1d3-dc2daf77690e"
      },
      "source": [
        "data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
        "        (\"Give it to me\".split(), \"ENGLISH\"),\n",
        "        (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
        "        (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
        "\n",
        "test_data = [(\"Yo creo que si\".split(), \"SPANISH\"),\n",
        "             (\"it is lost on me\".split(), \"ENGLISH\")]\n",
        "\n",
        "# word_to_ix maps each word in the vocab to a unique integer, which will be its\n",
        "# index into the Bag of words vector\n",
        "word_to_ix = {}\n",
        "for sent, _ in data + test_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "print(word_to_ix)\n",
        "\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "NUM_LABELS = 2\n",
        "\n",
        "\n",
        "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
        "\n",
        "    def __init__(self, num_labels, vocab_size):\n",
        "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
        "        # just always do it in an nn.Module\n",
        "        super(BoWClassifier, self).__init__()\n",
        "\n",
        "        # Define the parameters that you will need.  In this case, we need A and b,\n",
        "        # the parameters of the affine mapping.\n",
        "        # Torch defines nn.Linear(), which provides the affine map.\n",
        "        # Make sure you understand why the input dimension is vocab_size\n",
        "        # and the output is num_labels!\n",
        "        self.linear = nn.Linear(vocab_size, num_labels)\n",
        "\n",
        "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
        "        # to worry about that here\n",
        "\n",
        "    def forward(self, bow_vec):\n",
        "        # Pass the input through the linear layer,\n",
        "        # then pass that through log_softmax.\n",
        "        # Many non-linearities and other functions are in torch.nn.functional\n",
        "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
        "\n",
        "\n",
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence:\n",
        "        vec[word_to_ix[word]] += 1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "\n",
        "def make_target(label, label_to_ix):\n",
        "    return torch.LongTensor([label_to_ix[label]])\n",
        "\n",
        "\n",
        "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
        "\n",
        "# the model knows its parameters.  The first output below is A, the second is b.\n",
        "# Whenever you assign a component to a class variable in the __init__ function\n",
        "# of a module, which was done with the line\n",
        "# self.linear = nn.Linear(...)\n",
        "# Then through some Python magic from the PyTorch devs, your module\n",
        "# (in this case, BoWClassifier) will store knowledge of the nn.Linear's parameters\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "\n",
        "# To run the model, pass in a BoW vector\n",
        "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    sample = data[0]\n",
        "    bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
        "    log_probs = model(bow_vector)\n",
        "    print(log_probs)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22, 'Yo': 23, 'si': 24, 'on': 25}\n",
            "Parameter containing:\n",
            "tensor([[ 0.1346, -0.0129,  0.0996, -0.1787, -0.1247, -0.0449, -0.1256, -0.1245,\n",
            "         -0.0910,  0.1796,  0.1810,  0.0308,  0.0019, -0.0172,  0.1162, -0.0911,\n",
            "         -0.0369, -0.1494,  0.1205,  0.1169, -0.1767,  0.0200, -0.0804,  0.1069,\n",
            "         -0.0463,  0.0151],\n",
            "        [ 0.1512, -0.1256,  0.0190, -0.0499, -0.0927,  0.0883, -0.1939,  0.1076,\n",
            "          0.0483, -0.1933, -0.0082,  0.1953,  0.1832, -0.1867, -0.1938, -0.0308,\n",
            "          0.0099,  0.0465,  0.0196,  0.1619, -0.0100, -0.1510,  0.1365,  0.0346,\n",
            "          0.0086, -0.0577]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.1016, -0.1725], requires_grad=True)\n",
            "tensor([[-0.6177, -0.7747]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXUs7tkIm2nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_ix = {\"SPANISH\": 0, \"ENGLISH\": 1}"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3dWMXjdnT_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bc0ce568-df0a-4e9d-c900-eedd62490cd5"
      },
      "source": [
        "# Run on test data before we train, just to see a before-and-after\n",
        "with torch.no_grad():\n",
        "    for instance, label in test_data:\n",
        "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
        "        log_probs = model(bow_vec)\n",
        "        print(log_probs)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5475, -0.8637]])\n",
            "tensor([[-0.5881, -0.8105]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrWiqFqjpB3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b822f14d-fa4b-4e22-85ca-46f814604afe"
      },
      "source": [
        "print(bow_vec)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "         0., 0., 0., 1., 0., 0., 0., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBDP2cJJpKpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d4ee8f8f-7b32-49c1-a8c4-cd0d3a40f881"
      },
      "source": [
        "# Print the matrix column corresponding to \"creo\"\n",
        "print(next(model.parameters())[:, word_to_ix[\"creo\"]])\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Usually you want to pass over the training data several times.\n",
        "# 100 is much bigger than on a real data set, but real datasets have more than\n",
        "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable.\n",
        "for epoch in range(100):\n",
        "    for instance, label in data:\n",
        "        # Step 1. Remember that PyTorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Make our BOW vector and also we must wrap the target in a\n",
        "        # Tensor as an integer. For example, if the target is SPANISH, then\n",
        "        # we wrap the integer 0. The loss function then knows that the 0th\n",
        "        # element of the log probabilities is the log probability\n",
        "        # corresponding to SPANISH\n",
        "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
        "        target = make_target(label, label_to_ix)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        log_probs = model(bow_vec)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss = loss_function(log_probs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for instance, label in test_data:\n",
        "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
        "        log_probs = model(bow_vec)\n",
        "        print(log_probs)\n",
        "\n",
        "# Index corresponding to Spanish goes up, English goes down!\n",
        "print(next(model.parameters())[:, word_to_ix[\"creo\"]])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.1810, -0.0082], grad_fn=<SelectBackward>)\n",
            "tensor([[-0.1469, -1.9909]])\n",
            "tensor([[-2.3700, -0.0981]])\n",
            "tensor([ 0.5401, -0.3673], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAErdARrpUhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}